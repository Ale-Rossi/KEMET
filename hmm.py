#!/usr/bin/env python
# coding: utf-8

# In[ ]:


import os
from multiprocessing import Process
from multiprocessing import Pool
import cherrypy
import datetime
import argparse

# threshold checked for test datasets
_DEF_THR = 0.43

def create_tuple_modules(fixed_module_file):
    '''
    From the indication of Modules in which to look for incompleteness, generate a tuple for further use.
    ---------------------------------------------------------
    INPUT:  "fixed_module_file" - single column file with Modules of interest KEGG id
    '''
    list_modules = []
    with open(fixed_module_file) as f:
        for line in f.readlines():
            list_modules.append(line.strip())
    tuple_modules = tuple(list_modules)
    return tuple_modules

def create_tuple_modules_1BM(fasta_id, fixed_module_file, oneBM_modules_dir, report_tsv_directory):
    '''
    From Modules missing 1 orthologs block (via "kmc.py" - .tsv mode), generate a tuple of those for further use.
    ---------------------------------------------------------
    INPUT:  "module_file" - single column file with Modules of interest KEGG id
    '''
    os.chdir(report_tsv_directory)
    list_modules = []
    for file in os.listdir():
        if file.endswith(".tsv") and fasta_id in file:
            with open(file) as f:
                for line in f.readlines():
                    line = line.strip().split("\t")
                    MOD = line[0]
                    COMPLETENESS = line[2]
                    if COMPLETENESS == "1 BLOCK MISSING":
                        list_modules.append(MOD)

    os.chdir(oneBM_modules_dir)
    m = open(fasta_id+"_"+fixed_module_file, "w")
    for module in list_modules:
        m.write(module+"\n")
    m.close()

    tuple_modules = tuple(list_modules)
    return tuple_modules

def write_KOs_from_modules(fasta_id, tuple_modules, report_txt_directory, klists_directory):
    '''
    Generate a non-redundant list of KOs to be checked via HMM for Modules of interest - either fixed or related to missing annotated genomic content.
    ---------------------------------------------------------
    INPUT:  tuple_modules - output of "create_tuple_modules()" or "create_tuple_modules_1BM()", given the upstream indication of "fixed_module_file"
    OUTPUT: ".klist" file (missing KOs of interest) for the appropriate "report.txt" with in-depth Module-level indication.
    '''

    os.chdir(report_txt_directory)
    for file in os.listdir():
        if fasta_id in file:
            with open(file) as f:
                klist = []
                v = f.readlines()
                f.seek(0)
                i = 0

                for line in v:
                    i += 1
                    if line.startswith(tuple_modules):
                        start = i
                        j = i
                        for line in v[j:]:
                            j += 1
                            if line.startswith("M0"):
                                end = j
                                break

                        for l in v[start+1:end-2]:
                            l = l.strip().split("\t")[1].split(", ")
                            for KO in l:
                                if not KO in klist:
                                    klist.append(KO)

                os.chdir(klists_directory)
                g = open(file[10:-4]+".klist", "w")
                for KO in klist:
                    g.write(KO+"\n")
                g.close()
                os.chdir(report_txt_directory)

def write_KOs_from_fixed_list(fasta_id, fixed_ko_file, ktests_directory, klists_directory):
    '''
    Generate a non-redundant list of KOs to be checked via HMM starting from a fixed list.
    ---------------------------------------------------------
    INPUT:  fixed_ko_file - indication file, generated by "setup.py" to be compiled manually.
    OUTPUT: ".klist" file (missing KOs of interest) for the appropriate "report.txt" with in-depth Module-level indication.
    '''

    KO_to_check = []
    os.chdir(dir_base)
    with open(fixed_ko_file) as h:
        for line in h.readlines():
            KO_to_check.append(line.strip())

    os.chdir(ktests_directory)
    for file in os.listdir():
        if fasta_id in file:
            with open(file) as f:
                KO_present = []
                klist = []
                for line in f.readlines():
                    KO = line.strip()
                    KO_present.append(KO)

            for KO in KO_to_check:
                if not KO in KO_present:
                    klist.append(KO)

            os.chdir(klists_directory)
            g = open(file[:-6]+".klist", "w") # parse for file name w/o ".ktest"
            for KO in klist:
                g.write(KO+"\n")
            g.close()
    os.chdir(report_txt_directory)

def taxonomy_filter(taxonomy, dir_base, taxa_file, taxa_dir, update = False):
    '''
    Generate a file that includes KEGG Brite species codes (E-level) for a given C-level (phylum, most of the times) taxonomy indication.
    ---------------------------------------------------------
    INPUT:  taxonomy - indication of KEGG Brite taxonomy for MAG/Genome of interest (indicated in the "genomes.instruction" file).
    OUTPUT: ".keg" file (taxa_file) into "taxa_dir" folder.
    '''
    os.chdir(dir_base)
    taxa_allow=[]
    with open("br08601.keg") as f:
        v = f.readlines()
        f.seek(0)
        i = 0
        for line in v:
            i += 1
            if line.startswith("C") and taxonomy+" " in line:
                i_start = i-1
                break
        for line in v[i_start+1:]:
            i += 1
            if line.startswith("C"):
                i_stop = i-1
                break

        for line in v[i_start:i_stop]:
            if line.startswith("E"):
                taxa_allow.append(line.strip().replace("E        ","").split("  ")[0])

    if update:
        os.chdir(taxa_dir)
        g = open(taxa_file,"w") #taxonomy name
        for el in taxa_allow:
            g.write(el+"\n")
        g.close()

    return taxa_allow

def download_ntseq_of_KO(klist_file, dir_base_KO, dir_KO, klists_directory, taxa_dir, taxa_file, base_com_KEGGget):
    '''
    Following filering of "taxonomy_filter()", using KEGG API, download flatfiles with nt sequences of KOs of interest from allowed species (E-level).
    ---------------------------------------------------------
    INPUT:  klist_file (missing KOs of interest).
    OUTPUT: ".keg" file (taxa_file) into "taxa_dir" folder.
    '''
    cherrypy.log("START download nucleotidic sequences")
    os.chdir(taxa_dir)
    taxa_allow = []
    with open(taxa_file) as f:
        for line in f.readlines():
            taxa_allow.append(line.strip())

    os.chdir(klists_directory)
    with open(klist_file) as f:
        os.chdir(dir_base_KO)
        if not os.path.exists(dir_KO):
            os.mkdir(dir_KO)
        os.chdir(dir_KO)
        for line in f.readlines():
            line = line.strip()
            flatfile = str(line)+".keg"
            cmd_dir = "mkdir "+line
            os.chdir(dir_KO)
            if not os.path.exists(dir_KO+line):
                os.system(cmd_dir)
            else:
                continue
            os.chdir(line)
            os.system(base_com_KEGGget+line+" > "+flatfile)

            genes = parsekoflat(flatfile)
            os.system("rm "+flatfile)

            if __name__ == '__main__':
		# in order to request from KEGG in a legit way - modify if access to KEGG is available
                with Pool(processes=3) as p:
                    p.map(getntseq, genes)
                p.close()
    cherrypy.log("COMPLETE download nucleotidic sequences")

def download_aaseq_of_KO(klist_file, dir_base_KOaa, dir_KOaa, klists_directory, taxa_dir, taxa_file, base_com_KEGGget): # NOT IN USE - VIABLE FOR FRAMESHIFT TEST
    '''
    Following filering of "taxonomy_filter()", using KEGG API, download KO flatfiles with aa sequences of KOs of interest from allowed species (E-level).
    ---------------------------------------------------------
    INPUT:  klist_file (missing KOs of interest).
    OUTPUT: ".keg" file (taxa_file) into "taxa_dir" folder.
    '''
    cherrypy.log("START download aminoacidic sequences")
    os.chdir(taxa_dir)
    taxa_allow = []
    with open(taxa_file) as f:
        for line in f.readlines():
            taxa_allow.append(line.strip())

    os.chdir(klists_directory)
    with open(klist_file) as f:
        os.chdir(dir_base_KOaa)
        if not os.path.exists(dir_KOaa):
            os.mkdir(dir_KOaa)
        os.chdir(dir_KOaa)
        for line in f.readlines():
            line = line.strip()
            flatfile = str(line)+".keg"
            cmd_dir = "mkdir "+line
            os.chdir(dir_KOaa)
            if not os.path.exists(dir_KOaa+line):
                os.system(cmd_dir)
            else:
                continue
            os.chdir(line)
            os.system(base_com_KEGGget+line+" > "+flatfile)

            genes = parsekoflat(flatfile)
            os.system("rm "+flatfile)

            if __name__ == '__main__':
                with Pool(processes=3) as p:
                    p.map(getaaseq, genes)
                p.close()
    cherrypy.log("COMPLETE download aminoacidic sequences")

def parsekoflat(file):
    '''
    Parse KO flatfiles obtained using KEGG API, in order to generate the filtered list of sequences for a bulk download.
    ---------------------------------------------------------
    INPUT:  KEGG API KO flatfile.
    OUTPUT: genes - list of genes connected to the KO, for each appropriate species.
    '''
    genes = []
    with open(file) as f:
        v = f.readlines()
        n = 0
        for line in v:
            if not line.startswith("GENES"):
                n += 1
            else:
                break
        f.seek(0)
        for line in v[n:]:
            if line.startswith("REFERENCE") or line.startswith("///"):
                break
            line = line.replace("GENES       ","").strip()
            m = line.index(":")
            species = line[:m+1].casefold()
            line_s = line.split()
            for g_name in line_s[1:]:
                gene = (species+g_name).casefold()
                if "(" in gene:
                    p = gene.index("(")
                    gene = gene[:p]
                if "draft" in gene: # trial
                    continue
                genes.append(gene)
    return genes

def getntseq(gene):
    '''
    Download nt sequence of a given gene, from the list of KO-related genes list.
    ---------------------------------------------------------
    INPUT:  gene - element of "genes" list, generated via "parsekoflat()".
    OUTPUT: ".fna" file with nt sequence of the gene in input.
    '''
    gene_name = gene
    stop = gene_name.find(":")
    gene_taxa = gene_name[:stop]

    if gene_taxa in taxa_allow:
        cmd_get_ntseq = base_com_KEGGget+gene_name+"/ntseq"
        os.system(cmd_get_ntseq+" > "+gene_name+".fna")
        return 1

def getaaseq(gene): # NOT IN USE - part of "download_aaseq_of_KO()"- VIABLE FOR FRAMESHIFT TEST
    '''
    Download aa sequence of a given gene, from the list of KO-related genes list.
    ---------------------------------------------------------
    INPUT:  gene - element of "genes" list, generated via "parsekoflat()".
    OUTPUT: ".faa" file with aa sequence of the gene in input.
    '''
    gene_name = gene
    stop = gene_name.find(":")
    gene_taxa = gene_name[:stop]

    if gene_taxa in taxa_allow:
        cmd_get_aaseq = base_com_KEGGget+gene_name+"/aaseq"
        os.system(cmd_get_aaseq+" > "+gene_name+".faa")
        return 1

def filter_and_allign(taxa_dir, taxa_file, fasta_id, klist_file, klists_directory, msa_dir, dir_KO):
    '''
    Generate a nucleotidic multifasta with sequences from the given taxonomy range.
    The output does NOT contain redundant sequences
    Keep results in a folder organized by the FASTA-header of MAG/Genome.
    ---------------------------------------------------------
    INPUT:  KO and MSA folders; taxonomy indication (KEGG BRITE C-level - http://rest.kegg.jp/get/br:br08601)
    OUTPUT: Nucleotidic multifasta (.fna) with single representative sequences.
    '''
    cherrypy.log("START sequences filtering and allignment")
    ### filter for taxa of interest
    os.chdir(taxa_dir)
    taxa_allow = []
    with open(taxa_file) as f:
        for line in f.readlines():
            taxa_allow.append(line.strip())

    os.chdir(msa_dir)
    if not fasta_id in os.listdir():
        os.mkdir(fasta_id)

    # make a list of KOs to align - avoid doing so for every KO if pre-DL db is used
    os.chdir(klists_directory)
    KO_to_align = []
    with open(klist_file) as f:
        for line in f.readlines():
            KO = line.strip()
            if not KO in KO_to_align:
                KO_to_align.append(KO)

    os.chdir(dir_KO)
    for K in os.listdir():
        if not K in KO_to_align:
            continue

    # dictionary of non-redundant nt sequences
    # in order not to overvalue species with different strains in KEGG taxonomy
    # but only focusing on SEQUENCE DIVERSITY
        os.chdir("./"+K)
        sequniq = {} # {sequence : tax_code_of_identical_seqs}
        for nt_file in os.listdir():
            code = nt_file.split(":")[0]
            if not code in taxa_allow:
                continue

    ### exclude redundant nt copies
            with open(nt_file) as f:
                seq = f.readlines()[1:]
                seq1 = "".join(seq).replace("\n","")

                if not seq1 in sequniq.keys():
                    vett = [nt_file]
                    sequniq.update({seq1:vett})
                else:
                    vett = sequniq[seq1]
                    vett.append(nt_file)
                    sequniq.update({seq1:vett})

    ### Write a multiple sequence fasta
        os.chdir(msa_dir+fasta_id)
        if not K in os.listdir():
            os.mkdir(K)
        os.chdir(msa_dir+fasta_id+"/"+K)
        f = open("MSA_"+K+".fna", "a")
        for key, value in sequniq.items():
            f.write(">"+str(value[0][:-4])+"\n")
            f.write(key+"\n")
        f.close()
        os.chdir(dir_KO)
    cherrypy.log("COMPLETE Filter and allign")

def MSA_and_HMM(msa_dir_comm, base_com_mafft, base_com_hmmbuild):
    '''
    Run MAFFT-alignment and then build HMM nucleotidic profile from it.
    Keep results in a folder organized by the FASTA-header of MAG/Genome.
    ------------------------------------------------------
    INPUT:  nucleotidic multi-fasta folder; mafft & hmmbuild commands.
    OUTPUT: MSA and HMM profile for each KO that had a multi-fasta
    '''
    #TODO: enable to add options for hmmbuild & mafft commands
    cherrypy.log("START MSA and HMMs creation")
    os.chdir(msa_dir_comm)
    for K in os.listdir():
        os.chdir(K)
        ch_com_mafft = base_com_mafft.replace("K_NUMBER", K)
        ch_com_hmmbuild = base_com_hmmbuild.replace("K_NUMBER", K)
        os.system(ch_com_mafft)
        os.system(ch_com_hmmbuild)
        os.chdir(msa_dir_comm)
    cherrypy.log("COMPLETE MSA and HMM creation")

def nhmmer_for_genome(fasta_genome, msa_dir_comm, base_com_nhmmer):
    '''
    Run a nHMMER search for the newly generated HMM profiles against a given MAG/Genome.
    Keep results in a folder organized by the FASTA-header of MAG/Genome.
    ------------------------------------------------------
    INPUT:  Path for MAG/Genome of interest; HMMs from "MSA_and_HMM()"
    OUTPUT: Hits table stored as a parsable flat-file.
    '''
    #TODO: enable using nhmmer options
    cherrypy.log("START nhmmer search")
    os.chdir(msa_dir_comm)
    for K in os.listdir():
        os.chdir(K)
        ch_com_nhmmer = base_com_nhmmer.replace("K_NUMBER", K).replace("PATHFILE", fasta_genome)
        os.system(ch_com_nhmmer)
        os.chdir(msa_dir_comm)
    cherrypy.log("COMPLETE nhmmer")

def move_HMM_and_clean(hmm_dir_comm, msa_dir_comm):
    '''
    Order HMMs, moving them from MSA folder into a dedicated HMM folder.
    Remove multi-fasta sequences (".fna") generated for MAFFT.
    '''
    os.chdir(hmm_dir)
    if not os.path.exists(hmm_dir_comm):
        os.mkdir(hmm_dir_comm)
    os.chdir(msa_dir_comm)
    K_numbers = os.listdir()
    for K in K_numbers:
        os.chdir(hmm_dir_comm)
        if not os.path.exists(hmm_dir_comm+K):
            os.mkdir(K)
        os.chdir(msa_dir_comm+K)
        for file in os.listdir():
            if file.endswith(".hmm") or file.endswith(".hits"):
                hmm_file = file
                os.replace(msa_dir_comm+K+"/"+hmm_file, hmm_dir_comm+K+"/"+hmm_file)
            if file.endswith(".fna"):
                os.remove(file)
    cherrypy.log("COMPLETE move HMM and clean")

def movebackHMM(hmm_dir_comm, msa_dir_comm):
    '''
    Move ".hmm" & ".hits" files back to multi-alignment folder
    USE THIS to unroll from a complete pipe-run. - with the arg: "--retry_nhmmer"
    '''
    os.chdir(hmm_dir_comm)
    K_numbers = os.listdir()
    for K in K_numbers:
        os.chdir(hmm_dir_comm+K)
        for file in os.listdir():
            if file.endswith(".hmm") or file.endswith(".hits"):
                hmm_file = file
                os.replace(hmm_dir_comm+K+"/"+hmm_file, msa_dir_comm+K+"/"+hmm_file)
    cherrypy.log("COMPLETE move back HMM")

def nhmmer_significant_hits_corr(fasta_id, hmm_dir_comm, threshold= 100, corr_threshold= _DEF_THR, evalue_threshold = float(1e-30)):
    '''
    Initial nhmmer-derived hits storage.
    ------------------------------------------------------
    INPUT:  MAG/Genome of interest FASTA-header - its contigs FASTA file should be in "genomes_directory"
    OUTPUT: Table of HMM-derived hits' informations.
    ------------------------------------------------------
    PARAMETERS:

    threshold:        Minimum HMM-score for a significant hit
    corr_threshold:   Minimum HMM-score corrected for profile lenght for a significant hit
    evalue_threshold: Minimum HMM-e-value for a significant hit (NOT IMPLEMENTED BY DEFAULT - less stringent than the previous)
    '''
    #TODO: more data to better determine threshold! (manual control of quality: TIME INTENSIVE)

    os.chdir(hmm_dir_comm)
    sig_hits = {}

    g = open(fasta_id+"_HMM_hits.txt","a")
    g.write("K\tcorr_score,evalue\tfragment\tstrand\tl_bound\tr_bound\tp_lenght\thmmfrom\thmmto\n")
    g.close()

    for directory in sorted(os.listdir()):
        if directory.startswith("K"):
            K = directory
            os.chdir("./"+K)
            if not K+".hits" in os.listdir():
                os.chdir(hmm_dir_comm)
            else:
                evalue = 100
                score = 0
                corr_score = 0
                with open(K+".hits") as f:
                    v = f.readlines()[:-9]                             # NOT INCLUDING lines w/ command specifics - they rise a bug
                    add_ = int(v[1].index("-")-1)                      # CORRECT in case contig names are very long
                    for line in v:
                        if K in line[32+add_:38+add_]:
                            evalue = line[127+add_:136+add_].strip()
                            score = line[137+add_:143+add_].strip()

                            fragment = line[0:20+add_].strip()
                            strand = line[120+add_:126+add_].strip()
                            left_bound = int(line[80+add_:87+add_].strip())
                            right_bound = int(line[88+add_:95+add_].strip())
                            bounds = [str(left_bound-1),str(right_bound-1)]
                            hmmfrom = int(line[65+add_:71+add_].strip())
                            hmmto = int(line[72+add_:79+add_].strip())
                            hmm_bounds = [str(hmmfrom),str(hmmto)]
                            profile_lenght = int(hmmto - hmmfrom)

                            corr_score = round((float(score)/profile_lenght), 4)
                            break

                    if corr_score > corr_threshold and float(score) > threshold: # could be unified with evalue
                        sig_hits.update({K:[fragment,strand,bounds]})
                        # save into tabular file the most significant hits info (over threshold(s) )
                        os.chdir(hmm_dir_comm)
                        g = open(fasta_id+"_HMM_hits.txt","a")
                        g.write(K+"\t"+str(corr_score)+","+str(evalue)+"\t"+fragment+"\t"+strand+"\t"+str(left_bound-1)+"\t"+str(right_bound-1)+"\t"+str(profile_lenght)+"\t"+str(hmmfrom-1)+"\t"+str(hmmto-1)+"\n")
                        g.close()
                os.chdir(hmm_dir_comm)

    os.rename(hmm_dir_comm+fasta_id+"_HMM_hits.txt",hmm_hits_dir+fasta_id+"_HMM_hits.txt")
    cherrypy.log("COMPLETE nhmmer significant hits")
    return sig_hits

def HMM_hits_sequences(hmm_hits_dir, dir_genomes):
    '''
    Loads MAGs HMM-hits infos; check hits in contigs (FOR & REV).
    Stores them in a dictionary.
    ------------------------------------------------------------
    INPUT:  hits reports from "nhmmer_significant_hits_corr"
    OUTPUT: dictionary - {FASTA HEADER "MAG+KO" : sequence}
    '''
    #TODO: enable single MAG/Genome output - put out of the FOR loop

#### load all infos of different genomes' HMM-hits
    MAG_Khit_dict = {}
    HMM_hits_dict = {}

    os.chdir(hmm_hits_dir)
    for el in sorted(os.listdir()):
        if not el.endswith(".txt"):
            continue
        MAG = el[:-13] #slice for "_HMM_hits.txt"
        v_Khits = []
        with open(el) as f:
            for line in f.readlines()[1:]:
                line = line.strip().split("\t")
                v_Khit_info = []
                K = line[0]
                fragment = line[2]
                strand = line[3]
                l_bound = line[4]
                r_bound = line[5]

                v_Khit_info.append(K)
                v_Khit_info.append(fragment)
                v_Khit_info.append(strand)
                v_Khit_info.append(l_bound)
                v_Khit_info.append(r_bound)
                v_Khits.append(v_Khit_info)
        MAG_Khit_dict.update({MAG:v_Khits})

#### once loaded all infos of the hits, check the contigs//genomes for hits sequences
    for genome, val in MAG_Khit_dict.items():
        for hits in MAG_Khit_dict[genome]:
            strand_plus = False
            K = hits[0]
            fragment = hits[1]
            strand = hits[2]
            l_bound = int(hits[3])
            r_bound = int(hits[4])

            os.chdir(dir_genomes)
            for genome_file in os.listdir():
                if genome_file.startswith(genome+"."):
                    with open(genome_file) as f:
                        v_lines = f.readlines()
                        f.seek(0)
            i = -1
            for line in v_lines:
                line = line.strip()
                i += 1
                if ">" and fragment in line:
                    i_frag_start = i
                    j = i
                    for line in v_lines[i_frag_start+1:]:
                        j += 1
                        if ">" in line or j >= (len(v_lines)-1): # new contigs or file-end
                            i_frag_stop = j
                            break
                    break

    #### load contigs' "+" strand sequence
            try:
                fragment_w_hit = ""
                for line in v_lines[i_frag_start+1:i_frag_stop]:
                    line = line.strip()
                    for char in line:
                        fragment_w_hit += char

    #### different treatment for hits in "+" & "-" strands
                if strand == "+":
                    strand_plus = True
                if strand_plus == True:

                    SEQUENCE = fragment_w_hit[l_bound:r_bound]
                    HMM_hits_dict.update({">"+genome+"_"+K:SEQUENCE})

                elif strand_plus == False:

                    SEQUENCE_pre = fragment_w_hit[r_bound:l_bound]
                    pre = "ACTG"
                    post = "TGAC"
                    compl = SEQUENCE_pre.maketrans(pre, post)
                    seq_compl = SEQUENCE_pre.translate(compl)
                    SEQUENCE = seq_compl[::-1]
                    HMM_hits_dict.update({">"+genome+"_"+K:SEQUENCE})
            except:
                pass

    return HMM_hits_dict

def HMM_hits_translated_sequences(HMM_hits_dict):
    '''
    Translate HMM-hits in the 3 frames of the adequate strand.
    Stores them in a dictionary.
    --------------------------------------------------
    INPUT:  dictionary from "HMM_hits_sequences"
    OUTPUT: dictionary with translated hits
    '''
    #POSSIBILITY: NOT ONLY t11 table, but also another one
    t11 = {"TTT":"F", "TTC":"F", "TTA":"L", "TTG":"L",
           "TCT":"S", "TCC":"S", "TCA":"S", "TCG":"S",
           "TAT":"Y", "TAC":"Y", "TAA":"*", "TAG":"*",
           "TGT":"C", "TGC":"C", "TGA":"*", "TGG":"W",
           "CTT":"L", "CTC":"L", "CTA":"L", "CTG":"L",
           "CCT":"P", "CCC":"P", "CCA":"P", "CCG":"P",
           "CAT":"H", "CAC":"H", "CAA":"Q", "CAG":"Q",
           "CGT":"R", "CGC":"R", "CGA":"R", "CGG":"R",
           "ATT":"I", "ATC":"I", "ATA":"I", "ATG":"M",
           "ACT":"T", "ACC":"T", "ACA":"T", "ACG":"T",
           "AAT":"N", "AAC":"N", "AAA":"K", "AAG":"K",
           "AGT":"S", "AGC":"S", "AGA":"R", "AGG":"R",
           "GTT":"V", "GTC":"V", "GTA":"V", "GTG":"V",
           "GCT":"A", "GCC":"A", "GCA":"A", "GCG":"A",
           "GAT":"D", "GAC":"D", "GAA":"E", "GAG":"E",
           "GGT":"G", "GGC":"G", "GGA":"G", "GGG":"G",}

    HMM_hits_TRANSLATED_dict = {}
    for fasta_id, seq in HMM_hits_dict.items():
        ntseq1 = seq.upper()
        ntseq2 = seq[1:].upper()
        ntseq3 = seq[2:].upper()

        fasta1 = fasta_id+"__f1"
        fasta2 = fasta_id+"__f2"
        fasta3 = fasta_id+"__f3"
        aaseq1 = ""
        aaseq2 = ""
        aaseq3 = ""

        codons1 = [ntseq1[i:i+3] for i in range(0, len(ntseq1), 3)]
        for el in codons1:
            if len(el) < 3:
                codons1.remove(el)
        for codon in codons1:
            tr_codon = t11[codon]
            aaseq1 += tr_codon
        HMM_hits_TRANSLATED_dict.update({fasta1:aaseq1})

        codons2 = [ntseq2[i:i+3] for i in range(0, len(ntseq2), 3)]
        for el in codons2:
            if len(el) < 3:
                codons2.remove(el)
        for codon in codons2:
            tr_codon = t11[codon]
            aaseq2 += tr_codon
        HMM_hits_TRANSLATED_dict.update({fasta2:aaseq2})

        codons3 = [ntseq3[i:i+3] for i in range(0, len(ntseq3), 3)]
        for el in codons3:
            if len(el) < 3:
                codons3.remove(el)
        for codon in codons3:
            tr_codon = t11[codon]
            aaseq3 += tr_codon
        HMM_hits_TRANSLATED_dict.update({fasta3:aaseq3})

    return HMM_hits_TRANSLATED_dict

def HMM_hits_longest_translated_sequences(HMM_hits_dict, HMM_hits_TRANSLATED_dict):
    '''
    Compare the HMM translated hits and keep the longest hit without a stop codon.
    Stores them in a dictionary
    --------------------------------------------------
    INPUT:  dictionaries from "HMM_hits_sequences" and "HMM_hits_translated_sequences"
    OUTPUT: dictionary with longest translated hits
    '''
    max_len_dict = {}
    for fasta_nf in HMM_hits_dict.keys():
        max_len_dict.update({fasta_nf:[]})

    HMM_hits_TRANSLATED_MAXLEN_dict = {}

    for fasta_id, seq in HMM_hits_TRANSLATED_dict.items():
        fasta_nf = fasta_id.split("__")[0]

        #divided by stop codons
        seq = seq.split("*")
        #longer for single frame
        seq_max = max(seq, key = len)
        #add to list the longest
        max_len_dict[fasta_nf].append(seq_max)

    for fasta_nf in max_len_dict.keys():
        seq_max_allframes = max(max_len_dict[fasta_nf], key = len)
        frame = "__f"+str(max_len_dict[fasta_nf].index(seq_max_allframes)+1)
        HMM_hits_TRANSLATED_MAXLEN_dict.update({fasta_nf+frame:seq_max_allframes})

    return HMM_hits_TRANSLATED_MAXLEN_dict

def recap_hits_corr(fasta_id, hmm_hits_dir, HMM_hits_dict, HMM_hits_longestTRANSLATED_dict):
    '''
    Stores RECAP informations from HMM-hits dictionaries, with sequences.
    It gives the final tabular output of the entire process.
    ------------------------------------------------------
    INPUT:  MAG/Genome of interest name - its contigs FASTA file should be in "genomes_directory" / input_directory
    OUTPUT: Table of HMM-derived hits' informations.
    '''
    #TODO: enable single MAG/Genome output - put out of the FOR loop
    import datetime
    datetoday = str(datetime.datetime.now())[:10]

    os.chdir(hmm_hits_dir)
    f = open("file_recap_"+datetoday+".tsv", "a")
    header = "MAG\tKO\tcorr_score,evalue\tfragment\tstrand\tl_bound\tr_bound\tp_lenght\thmmfrom\thmmto\tframe\tseq\txseq\n"
    if f.tell() == 0: 
        f.write(header)

    for file in sorted(os.listdir()):
        if file.endswith(".txt") and fasta_id in file:
            with open(file) as g:
                #f.write(file[:-13]+"\n")
                for line in g.readlines()[1:]:
                    KO = line.strip().split("\t")[0]
                    for hit in HMM_hits_dict.keys():
                        if hit.startswith(">"+file[:-13]+"_"+KO): ###
                            seq = HMM_hits_dict[hit].upper()
                            break
                    for hit in HMM_hits_longestTRANSLATED_dict.keys():
                        if hit.startswith(">"+file[:-13]+"_"+KO): ###
                            frame = hit[-1]
                            xseq = HMM_hits_longestTRANSLATED_dict[hit]
                            break

                    f.write(file[:-13]+"\t"+line.strip()+"\t"+frame+"\t"+seq+"\t"+xseq+"\n")
    f.close()

########################################################################################

if __name__ == "__main__":
    import os
    import datetime
    import argparse

    ###########################
    # NECESSARY_PATHS & FILES #
    ###########################
    dir_base = os.getcwd()+"/"
    fixed_module_file = "module_file.instruction"
    fixed_ko_file = "ko_file.instruction"
    instruction_file = "genomes.instruction"

    ###################
    # directories KMC #
    ###################
    KAnnotation_directory = dir_base+"KEGG_mappings/"
    ktests_directory = dir_base+"ktests/"
    klists_directory = dir_base+"klists/"
    report_txt_directory = dir_base+"reports_txt/"
    report_tsv_directory = dir_base+"reports_tsv/"

    ###################
    # directories HMM #
    ###################
    taxa_dir = dir_base+"taxonomies/"
    dir_base_KO = dir_base+"Knumber_ntsequences/"
    dir_base_KOaa = dir_base+"Knumber_aasequences/"
    msa_dir = dir_base+"multiple_fasta/"
    hmm_dir = dir_base+"HMM/"
    hmm_hits_dir = dir_base+"HMM_HITS/"
    dir_genomes = dir_base+"genomes/"
    oneBM_modules_dir = dir_base+"oneBM_modules/"

    #################
    # BASE COMMANDS #
    #################
    base_com_KEGGget = "curl --silent http://rest.kegg.jp/get/"
    base_com_mafft = "mafft --quiet --auto MSA_K_NUMBER.fna > K_NUMBER.msa"                       #POSSIBILITY: enable using mafft option    - e.g. add argument to modify "base_com ..." variable
    base_com_hmmbuild = "hmmbuild --informat afa K_NUMBER.hmm K_NUMBER.msa > /dev/null"           #POSSIBILITY: enable using hmmbuild option - e.g. add argument to modify "base_com ..." variable
    base_com_nhmmer = "nhmmer --tblout K_NUMBER.hits K_NUMBER.hmm PATHFILE > /dev/null"           #POSSIBILITY: enable using nhmmer options  - e.g. add argument to modify "base_com ..." variable

########################################################################################

    parser = argparse.ArgumentParser(
        description='''HMM-based check for ortholog genes after KEGG Module Completeness evaluation.
        To be used after kmc.py with -o txt option''')
    parser.add_argument('MAG_genome_FASTA',
                        help='''Run HMM-based search for KOs in Modules of interest in the genome indicated with this expression (no FASTA extension).''')
    parser.add_argument('--update_taxonomy_codes', action ="store_true",
                        help='''Update taxonomy filter codes - WHEN TO USE: after downloading a new BRITE taxonomy with "setup.py".''')

    parser.add_argument('--onebm_modules_list', action ="store_true",
                        help='''Use all KEGG Modules missing 1 block for the HMM-based check (only KOs missing in the indicated MAG/Genome).''')
    parser.add_argument('--fixed_modules_list', action ="store_true",
                        help='''Use a fixed list of KEGG Modules to use for the HMM-based check (only KOs missing in the indicated MAG/Genome).''')
    parser.add_argument('--fixed_ko_list', action ="store_true",
                        help='''Use a fixed list of KOs to use for the HMM-based check (only KOs missing in the indicated MAG/Genome).''')
    parser.add_argument('--threshold_value', default = _DEF_THR,
                        help='''Define a threshold for the corrected score resulting from HMM-hits, which is indicative of good quality.''')

    parser.add_argument('--skip_nt_download', action ="store_true",
                        help='''Skip downloading KEGG KOs nt sequences.''')
    parser.add_argument('--do_aa_download', action ="store_true",
                        help='''Allow downloading KEGG KOs aa sequences.''')
    parser.add_argument('--skip_msa_and_hmmbuild', action ="store_true",
                        help='''Skip MAFFT and HMMER hmmbuild commands.''')
    parser.add_argument('--retry_nhmmer', action ="store_true",
                        help='''Move HMM-files and re-run nHMMER command.''')
    parser.add_argument('-I','--path_input', default = "dir_base_KO",
                        help='''Absolute path to input file(s) FOLDER.''')
    #parser.add_argument('-O','--path_output',
    #                    help='''Absolute path to ouput file(s) FOLDER.''', default = dir_base)

    parser.add_argument('-v','--verbose', action ="store_true",
                        help='''Print more informations - useful for debug and progress.''')
    parser.add_argument('-q','--quiet', action ="store_true",
                        help='''Silence soft-errors (for MAFFT and HMMER commands).''')
    args = parser.parse_args()

########################################################################################

#### READ AND WRITE INSTRUCTIONS
    os.chdir(dir_base)
    FASTA = str(args.MAG_genome_FASTA)
    with open(instruction_file) as f:
        for line in f.readlines()[1:]:
            if line.startswith(FASTA):
                line = line.strip().split("\t")
                for file in os.listdir(dir_genomes):
                    if file.startswith(FASTA):
                        fasta_genome = dir_genomes+file

                fasta_id = line[0]
                klist_file = FASTA+".klist"
                taxonomy = line[1]
                taxa_file = taxonomy+".keg"                                                  # Genome taxonomy (as KEGG BRITE)
                if args.fixed_modules_list:
                    os.chdir(dir_base)
                    tuple_modules = create_tuple_modules(fixed_module_file)
                    write_KOs_from_modules(fasta_id, tuple_modules, report_txt_directory, klists_directory)
                if args.onebm_modules_list:
                    tuple_modules = create_tuple_modules_1BM(fasta_id, fixed_module_file, oneBM_modules_dir, report_tsv_directory)
                    write_KOs_from_modules(fasta_id, tuple_modules, report_txt_directory, klists_directory)
                if args.fixed_ko_list:
                    write_KOs_from_fixed_list(fasta_id, fixed_ko_file, ktests_directory, klists_directory)

                if args.path_input != "dir_base_KO":
                    dir_base_KO = args.path_input
                dir_KO = dir_base_KO+taxonomy.replace(" ","_")+"/"                           # KO folder for taxonomy,    save time!
                dir_KOaa = dir_base_KOaa+taxonomy.replace(" ","_")+"/"                       # KO folder for taxonomy,    save time!
                msa_dir_comm = msa_dir+fasta_id+"/"                                          # MSA folder for MAG/Genome, more ordered!
                hmm_dir_comm = hmm_dir+fasta_id+"/"                                          # HMM folder for MAG/Genome, more ordered!
                CORR_THRESHOLD = float(args.threshold_value)

##########################################################################################

#### VERBOSITY SETTINGS
                if args.verbose:
                    base_com_KEGGget = "curl --silent http://rest.kegg.jp/get/"
                    base_com_mafft = "mafft --auto MSA_K_NUMBER.fna > K_NUMBER.msa"
                    base_com_hmmbuild = "hmmbuild --informat afa K_NUMBER.hmm K_NUMBER.msa"
                    base_com_nhmmer = "nhmmer --tblout K_NUMBER.hits K_NUMBER.hmm PATHFILE"

                if args.quiet:
                    base_com_KEGGget = "curl --silent http://rest.kegg.jp/get/"
                    base_com_mafft = "mafft --quiet --auto MSA_K_NUMBER.fna > K_NUMBER.msa 2>/dev/null"
                    base_com_hmmbuild = "hmmbuild --informat afa K_NUMBER.hmm K_NUMBER.msa > /dev/null 2>&1"
                    base_com_nhmmer = "nhmmer --tblout K_NUMBER.hits K_NUMBER.hmm PATHFILE > /dev/null 2>&1"

#### OPERATE SINGLE FUNCTIONS
                cherrypy.log("+++++START "+fasta_id)
                if args.update_taxonomy_codes:
                    taxa_allow = taxonomy_filter(taxonomy, dir_base, taxa_file, taxa_dir, update = True)    # POSSIBILITY: update organisms code
                else:
                    os.chdir(taxa_dir)
                    if not taxa_file in os.listdir():
                        taxa_allow = taxonomy_filter(taxonomy, dir_base, taxa_file, taxa_dir, update = True)
                    else:
                        taxa_allow = taxonomy_filter(taxonomy, dir_base, taxa_file, taxa_dir)

                if not args.skip_nt_download:
                    download_ntseq_of_KO(klist_file, dir_base_KO, dir_KO, klists_directory, taxa_dir, taxa_file, base_com_KEGGget)
                if args.do_aa_download:
                    download_aaseq_of_KO(klist_file, dir_base_KOaa, dir_KOaa, klists_directory, taxa_dir, taxa_file, base_com_KEGGget)

                if args.retry_nhmmer:
                    movebackHMM(hmm_dir_comm, msa_dir_comm)                                                # POSSIBILITY: after a whole KEMET run, to try other paramethers
                if not args.skip_msa_and_hmmbuild:
                    filter_and_allign(taxa_dir, taxa_file, fasta_id, klist_file, klists_directory, msa_dir, dir_KO)
                    MSA_and_HMM(msa_dir_comm, base_com_mafft, base_com_hmmbuild)
                nhmmer_for_genome(fasta_genome, msa_dir_comm, base_com_nhmmer)                             # POSSIBILITY: enable using nhmmer options e.g. PARALLEL PROCESSES "--cpu = N"
                move_HMM_and_clean(hmm_dir_comm, msa_dir_comm)

#### FIRST REPORT FILE
                nhmmer_significant_hits_corr(fasta_id, hmm_dir_comm, corr_threshold = CORR_THRESHOLD)

                HMM_hits_dict = HMM_hits_sequences(hmm_hits_dir, dir_genomes)
                HMM_hits_TRANSLATED_dict = HMM_hits_translated_sequences(HMM_hits_dict)
                HMM_hits_longestTRANSLATED_dict = HMM_hits_longest_translated_sequences(HMM_hits_dict, HMM_hits_TRANSLATED_dict)

#### TOTAL REPORT FILE
                recap_hits_corr(fasta_id, hmm_hits_dir, HMM_hits_dict, HMM_hits_longestTRANSLATED_dict)

                cherrypy.log("END "+fasta_id)
